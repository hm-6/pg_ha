# pg_ha_repair.yaml
- name: Repair unhealthy Patroni nodes (reinit + optional HAProxy drain/enable)
  hosts: localhost
  gather_facts: no
  become: false

  vars:
    patroni_conf: /etc/patroni/patroni.yml
    # Optional: HAProxy Runtime-Socket; Schritte werden nur ausgeführt, wenn gesetzt
    haproxy_socket: "{{ hostvars[groups['postgreses'][0]].haproxy_runtime_socket_host | default(omit) }}"
    haproxy_backends:
      - pgsql_write
      - pgsql_read

    # Optionaler Hardcore-Mode (Daten-Wipe nur wenn explizit erlaubt)
    repair_allow_pgdata_wipe: false
    patroni_rest_port_default: 8008

  tasks:
    - name: Collect cluster state (via first DB host)
      delegate_to: "{{ groups['postgreses'][0] }}"
      become: true
      ansible.builtin.command: "sudo -u postgres patronictl -c {{ patroni_conf }} list --format=json"
      register: patroni_list_json
      changed_when: false

    - name: Validate patroni JSON present
      ansible.builtin.assert:
        that:
          - patroni_list_json.stdout is defined
          - (patroni_list_json.stdout | length) > 0
        fail_msg: "patronictl returned no JSON."

    - name: Derive cluster facts
      vars:
        members: "{{ patroni_list_json.stdout | from_json }}"
      ansible.builtin.set_fact:
        cluster_name: "{{ (members | first)['Cluster'] }}"
        patroni_leader: "{{ (members | selectattr('Role','equalto','Leader') | map(attribute='Member') | first) }}"
        healthy_members: "{{ members | selectattr('State','in',['running','streaming']) | map(attribute='Member') | list }}"
        all_members: "{{ groups['postgreses'] }}"

    - name: Fail early if no healthy node present (need controller for patronictl)
      ansible.builtin.assert:
        that: healthy_members | length >= 1
        fail_msg: "Kein gesunder Node gefunden → kein 'patronictl reinit' möglich. Abbruch."

    # ---- (optional) Probes – nur Info, nicht entscheidungsrelevant ----
    - name: Check SSH reachability (TCP/22)
      ansible.builtin.wait_for:
        host: "{{ hostvars[item].ansible_host | default(item) }}"
        port: 22
        timeout: 3
      changed_when: false
      failed_when: false
      loop: "{{ all_members }}"
      loop_control: { label: "{{ item }}" }
      register: ssh_checks

    - name: Check Patroni REST reachability (TCP only)
      ansible.builtin.wait_for:
        host: "{{ hostvars[item].ansible_host | default(item) }}"
        port: "{{ (hostvars[item].patroni_rest_port | default(patroni_rest_port_default)) | int }}"
        timeout: 2
      changed_when: false
      failed_when: false
      loop: "{{ all_members }}"
      loop_control: { label: "{{ item }}" }
      register: rest_checks

    - name: Compute repair targets (only by Patroni health)
      ansible.builtin.set_fact:
        repair_targets: "{{ all_members | difference(healthy_members) }}"

    - name: Show repair targets
      ansible.builtin.debug:
        msg: "Repair targets: {{ repair_targets | default([]) }}"

    - name: Nothing to repair → end play
      when: (repair_targets | default([])) | length == 0
      ansible.builtin.meta: end_play

    # ---- Optional: HAProxy drain before reinit ----
    - name: (Optional) Drain target from HAProxy backends
      when: haproxy_socket is defined
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.shell: |
        {% for b in haproxy_backends -%}
        echo "disable server {{ b }}/{{ item }}" | socat - {{ haproxy_socket }}
        {% endfor -%}
      args: { executable: /bin/bash }
      changed_when: true
      failed_when: false
      loop: "{{ repair_targets }}"
      loop_control: { label: "drain {{ item }}" }

    # ---- Reinit (gentle) für alle Repair-Targets ----
    - name: Patroni reinit (gentle)
      delegate_to: "{{ healthy_members[0] }}"
      become: true
      ansible.builtin.command: >-
        sudo -u postgres patronictl -c {{ patroni_conf }}
        reinit {{ cluster_name }} {{ item }}
      register: reinit_gentle
      changed_when: "'scheduled' in (reinit_gentle.stdout | default('')) or reinit_gentle.rc == 0"
      failed_when: false
      loop: "{{ repair_targets }}"
      loop_control: { label: "{{ item }}" }

    - name: Compute force targets (gentle failed)
      ansible.builtin.set_fact:
        force_targets: "{{ reinit_gentle.results | selectattr('rc','defined') | selectattr('rc','ne',0) | map(attribute='item') | list }}"

    - name: Patroni reinit (force) for failed ones
      when: (force_targets | length) > 0
      delegate_to: "{{ healthy_members[0] }}"
      become: true
      ansible.builtin.command: >-
        sudo -u postgres patronictl -c {{ patroni_conf }}
        reinit --force {{ cluster_name }} {{ item }}
      register: reinit_force
      changed_when: "'scheduled' in (reinit_force.stdout | default('')) or reinit_force.rc == 0"
      failed_when: false
      loop: "{{ force_targets }}"
      loop_control: { label: "{{ item }}" }

    # ---- Optionaler Hardcore-Mode: PGDATA wipe + Patroni neu starten ----
    - name: Stop patroni (wipe path)  # nur wenn explizit erlaubt
      when: repair_allow_pgdata_wipe | bool
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.service:
        name: patroni
        state: stopped
      failed_when: false
      loop: "{{ repair_targets }}"
      loop_control: { label: "{{ item }}" }

    - name: (DANGEROUS) wipe PGDATA
      when: repair_allow_pgdata_wipe | bool
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.file:
        path: "{{ hostvars[item].patroni_pgdata | default('/var/lib/postgresql/data') }}"
        state: absent
      loop: "{{ repair_targets }}"
      loop_control: { label: "{{ item }}" }

    - name: Recreate PGDATA
      when: repair_allow_pgdata_wipe | bool
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.file:
        path: "{{ hostvars[item].patroni_pgdata | default('/var/lib/postgresql/data') }}"
        state: directory
        owner: postgres
        group: postgres
        mode: "0700"
      loop: "{{ repair_targets }}"
      loop_control: { label: "{{ item }}" }

    - name: Start patroni (after wipe)
      when: repair_allow_pgdata_wipe | bool
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.service:
        name: patroni
        state: started
        enabled: true
      loop: "{{ repair_targets }}"
      loop_control: { label: "{{ item }}" }

    # ---- Warten bis Nodes wieder gesund sind ----
    - name: Wait for REST API of repaired nodes
      ansible.builtin.wait_for:
        host: "{{ hostvars[item].ansible_host | default(item) }}"
        port: "{{ (hostvars[item].patroni_rest_port | default(patroni_rest_port_default)) | int }}"
        delay: 2
        timeout: 300
      failed_when: false
      loop: "{{ repair_targets }}"
      loop_control: { label: "wait REST {{ item }}" }

    - name: Wait until node is healthy (running/streaming) after reinit
      delegate_to: "{{ healthy_members[0] }}"
      become: true
      ansible.builtin.command: "sudo -u postgres patronictl -c {{ patroni_conf }} list --format=json"
      register: after_repair
      changed_when: false
      retries: 60
      delay: 2
      until: >
        (
          (after_repair.stdout | from_json)
          | selectattr('Member','equalto', item)
          | map(attribute='State') | list
        )[0] in ['running','streaming']
      loop: "{{ repair_targets }}"
      loop_control: { label: "wait healthy {{ item }}" }

    # ---- Optional: In HAProxy wieder aktivieren ----
    - name: (Optional) Re-enable repaired nodes in HAProxy
      when: haproxy_socket is defined
      delegate_to: "{{ item }}"
      become: true
      ansible.builtin.shell: |
        {% for b in haproxy_backends -%}
        echo "enable server {{ b }}/{{ item }}" | socat - {{ haproxy_socket }}
        {% endfor -%}
      args: { executable: /bin/bash }
      changed_when: true
      failed_when: false
      loop: "{{ repair_targets }}"
      loop_control: { label: "enable {{ item }}" }

    # ---- Abschlussprüfung ----
    - name: Final cluster state
      delegate_to: "{{ healthy_members[0] }}"
      become: true
      ansible.builtin.command: "sudo -u postgres patronictl -c {{ patroni_conf }} list --format=json"
      register: final_list
      changed_when: false

    - name: Assert all members healthy at the end
      vars:
        final: "{{ final_list.stdout | from_json }}"
      ansible.builtin.assert:
        that:
          - (final | selectattr('State','in',['running','streaming']) | list | length) == (all_members | length)
        fail_msg: "Nach Repair sind nicht alle Knoten gesund."
